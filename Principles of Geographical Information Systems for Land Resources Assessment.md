# Principles of Geographical Information Systems for Land Resources Assessment

## 2. Data Structures for Thematic Maps
**Data structures for geographical information systems**
Unlike many other kinds of data handled routinely by modern information systems, geographical data are complicated by the fact that they must include information about position, possible topological connections, and attributes of the objects recorded. The topological and spatial aspects of geographical data processing distinguish systems designed for graphics and mapping from those other modern data processing systems such as those used for banking. library searches, airline bookings or medical records.
Geographical data are referenced to locations on the earth's surface by using a standard system of coordinates. The coordinate system may be purely local, as in the case of a study of a limited area, or it may be that of a national grid or an internationally accepted projection such as the Universal Transverse Mercator Coordinate System (UTM). Geographical data are very often recognized and described in terms of wellestablished geographical "objects", or phenomena. All geographical studies have used phenomenological concepts such as "town", "river", "floodplain", "ecotope", "soil association" as fundamental building blocks for analysing and synthesizing complex information. These phenomenological building blocks are very often grouped or divided into units at other scales according to hierarchically defined taxonomies, for example the hierarchy of country-province-town-district, or the hierarchy of most soil classification systems or of plants and animals. We should note, in passing, that although many of these perceived geographical phenomena are described by scientists as though they were explicit objects (such as "table", or "chair") their exact form and extent may be debatable. or may change with time. The implications of this are discussed in Chapter 6 on data quality and errors.

**Points, lines, and areas** 
All geographical data can be reduced to three basic topological concepts -- the point, the line, and the area. Every geographical phenomenon can in principle be represented by a point, line or area plus a label saying what it is. So an oil well could be represented by a point entity consisting of a single *XY* coordinate pair and the label "oil well"; a section of railway line could be represented by a line entity consisting of a starting *XY* coordinate and an end *XY* coordinate and the label "railway"; a floodplain could be represented by an area entity covering a set of *XY* coordinates plus the label "floodplain". The labels could be the actual names as given here, or they could be numbers that cross-reference with a legend, or they could be special symbols. All these techniques are used in conventional mapping.

**Definition of a map**
A *map* is a set of *points*, *lines*, and *areas* that are defined both by their location in space with reference to a coordinate system and by their non-spatial attributes (Fig. 2.1 (a-c)). A map is usually represented in two dimensions but there is no reason to exclude higher dimensions except through the difficulty of portraying them on a flat piece of paper.
The *map legend* is the key linking the non-spatial attributes to the spatial entities. Non-spatial attributes may be indicated visually by colours, symbols or shading, the meaning of which is defined in the legend. For geographical information systems, non-spatial attributes need to be coded in a form in which they can be used for data analysis. A *region* is a set of pixels, areas or polygons that are described by a single legend unit. A region may be made up of several discrete occurrences (Fig. 2.1.(d)), which may be uniform, or which may contain polygons belonging to regions of another kind (Fig. 2.1(e)). Although the eye can easily distinguish the topological relationships between the regions in Fig. 2.1(d-f), these relationships must be explicitly built into any digital representation.
![Fig. 2.1](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.1.png)

**Fig. 2.1** A map is a set of points, lines, and areas defined both by position with reference to a coordinate system and by their non-spatial attributes (a, b, c). A region is a set of loci on a map that belong to the same class or have the same attribute (d, e, f). (d) is a disjoint region, (e) a perforated region; (f) shows three different regions.

**Geographical data in the computer**
When geographical data are entered into a computer the user will be most at ease if the geographical information system can accept the phenomenological data structures that he has always been accustomed to using. But computers are not organized like human minds and must be programmed to represent phenomenological structures appropriately. Moreover, the way the geographical data are visualized by the user is frequently not the most efficient way to structure the computer database. Finally, the data have to be written and stored on magnetic devices that need to be addressed in a specific way. We can represent these four stages as follows:
$${A} \longleftrightarrow$$ {B} $$\longleftrightarrow$$ {C} $$\longleftrightarrow {D}$$
User's perceived phenomenon structure $$\longleftrightarrow$$ GIS representation of phenomenon structure $$\longleftrightarrow$$ Database structure $$\longleftrightarrow$$ Hardware structure

We shall consider stages A, B, and C here; hardware aspects fall outside the scope of this discussion and the interested reader should consult a text on computer architecture.

**Database structures: data organization in the computer**
Before considering in detail the ways in which geographical data can be stored in the computer, we must first consider the ways in which data can be organized for storage and access in general. Although it is not essential for a user of a geographical information system to understand in detail how the data can be ordered inside the computer, any more than the driver of a car needs to know about the workings of the internal combustion engine, a little knowledge of data structuring methods will help him to understand better how the systems work, and what their limitations and advantages might be. The following section presents only a brief introduction. Readers interested in a more thorough treatment should consult a standard work in information storage and retrieval such as Salton and McGill (1983). Giloi (1978), CODASYL (1971), Gersting (1984), Kroenke (1977), Date (1981). Ullman (1980) or Wirth (1976).
The essential features of any data storage system are that they should be able to allow data to be accessed and cross-referenced quickly. There are several ways of achieving this, some of which are more efficient than others. Unfortunately, there seems to be no one "best" method that can be used for all situations. This explains in part the massive investment in labour and money in effective *database management systems*. which are the computer programs that control data input, output, storage, and retrieval from a digital database.

**Files and data access**
*Simple lists*
The simplest form of database is a simple list of all the items. As each new item is added to the database, it is simply placed at the end of the file, which gets longer and longer. It is very easy to add data to such a system, but retrieving data is inefficient. For a list containing n items, it takes an average of $$(n+1)/2$$ search operations to find the item you want. So, for an information system containing 10 000 soil profiles on cards, given that it takes Is to read the card name or number, it would take an average of $$(10000+1)/2 s$$ or about an hour and a half to find the card you want.
Most people know that searching through unstructured lists trying to find the needle in the haystack" is very inefficient. It is thus an obvious step to order or structure the data and to provide a key to that structure in order to speed up data retrieval.
*Ordered sequential files*
Words in a dictionary, or names in a telephone book are structured alphabetically. Addition of a new item means that extra room must be created to insert it, but the advantage is that stored items can be reached very much faster. Very often, ordered sequential files are accessed by binary search procedures. Instead of beginning the search at the beginning of the list, the record in the middle is examined first. If the key value (e.g. the sequence of letters in a word) matches, then the middle record is the one being sought. If the values do not match, a simple test is made to see whether the required item occurs before or after the middle element. The appropriate half of the file is retained, and the search repeated, until the item has been located. Binary search requires log: $$(n+1)$$ steps. If the file is 10 000 items long, and the search time per item is $$1s$$. the average time to find an item is approximately $$14s$$, compared with the $$1.5h$$ previously!
*Indexed files*
Simple sequential and ordered sequential files require that data be retrieved according to a key attribute. In the case of a dictionary, the key attribute is the spelling. But in many applications, particularly in geographical information, the individual items (pixels, points, lines or areas) will have not only a key attribute such as an identification number or a name but will also carry information about associated attributes. Very often it is the information about the associated attributes that is required, not just the name. For example, we may have an ordered list of soil profiles that has been structured by soil series name, but we would like to retrieve information about soil depth, drainage, pH, texture, or erosion. Unless we adopt another database strategy, our search procedures revert to those of the simple sequential list.
With indexed files, access to the original data file can be speeded up in two ways. If the data items in the files themselves provide the main order of the file, then the files are known as direct files. The location of items in the main file can also be specified according to topic, which is given in a second file, known as an inverted file. Just as in a book, examination of the index can determine the items (pages) which satisfy the search request.
In the direct file, the record for each item contains sufficient information for the search to jump over unnecessary items. For example, consider a data file containing soil series names that have been ordered alphabetically. Each item contains not only the series name and other information but also a number indicating the storage location of series names beginning with that letter. The search for a particular record is then made much simpler by constructing a simple index file that lists the correspondence between first letter of series name and storage location. The search proceeds by a sequential search of the index, followed by a sequential search of the appropriate data block. The average number of search steps is then *$$(n1+1)/2+(n+1)/2$$*, where n, is the number of steps in the index and n, is the number of items in the data block referenced by the index.
The use of the inverted file index requires first that it be constructed by performing an initial sequential search on the data for each topic. The results are then assembled in the inverted file or index, which provides the key for further data access (Table 2.1).
Indexed files permit rapid access to databases. Unfortunately, they have inherent problems when used with files in which records are continually being added or deleted, such as often happens with interactive mapping systems. Addition or deletion of a record in a direct file means that both the file and its index must be modified. When new records are written to a file accessed by an inverted file index, the new record does not have to be placed at a special position; it can be simply added to the end of the file, but the index must be updated. File modification can be an expensive undertaking with large data files, particularly in an interactive environment. A further disadvantage of indexed files is that very often data can only be accessed via the key contained in the index files; other information may only be retrievable using sequential search methods.
**Table 2.1**  *Indexed files*
![Table. 2.1](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Tabla_2.1.png)

**Database structures**
A database consists of data in many files. In order to be able to access data from one or more files easily, it is necessary to have some kind of structure or organization. Three main kinds of database structure are commonly recognized, termed hierarchical, network, and relational.
*Hierarchical data structure*
When the data have a parent/child or one-to-many relation, such as soil series within a soil family, or pixels within a region, hierarchical methods provide quick and convenient means of data access. Hierarchical systems of data organization are well-known, of course, to environmental science, being the methods used for plant and animal taxonomies, soil classification, and so on. Hierarchical systems assume that each part of the hierarchy can be reached using a key (a set of discriminating criteria) that fully describes the data structure. Hierarchical systems assume that there is a good correlation between the key attributes (discriminating criteria) and the associated attributes that the items may possess. Hierarchical systems have the advantage that they are easy to understand, and they are easy to update and expand. Data access via the keys is easy for key attributes, but unfortunately is very difficult for associated attributes. Consequently, hierarchical systems are good for data retrieval if the structure of all possible queries can be known beforehand. This is commonly the case with bibliographic, bank or airline retrieval systems. For environmental data, however, the exploratory nature of many retrieval requests cannot be accommodated by the rigid hierarchy and the critical user may reject the system as impossibly inflexible. For example, Beyer (1984) reports that the Royal Botanical Gardens in Kew initially set up a hierarchical database based on the rules of plant taxonomy for their herbarium collection of more than a million items. This seemed sensible until the Director wished to make a trip to Mexico to gather new material for the herbarium and asked the database which plants that Kew already had from that land. Unfortunately for the suppliers and the users of the database, the director received no answer because the attribute "place of collection" is not part of the plant taxonomy key!
Further disadvantages of hierarchical database structures are that large index files have to be maintained, and certain attribute values may have to be repeated many times, leading to data redundancy. which increases storage and access costs (Fig. 2.2).
![Figura_2.2](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.2.png)
**Fig. 2.2** Hierarchical database structure commonly used in soil science.

*Network systems*
In hierarchical systems, travel within the database is restricted to the paths up and down the taxonomic pathways. In many situations much more rapid linkage is required, particularly in data structures for graphics features where adjacent items in a map or figure need to be linked together even though the actual data about their coordinates may be written in very different parts of the database. Network systems fulfil this need.
Consider Fig. 2.3(a), which consists of a simple map of two polygons. Figure. 2.3(a) shows the map as it appears to the human brain; that is the two polygons are defined by a set of lines, one of which is common to both. The lines, in turn, are defined by coordinate pairs, with each coordinate pair common to two lines. Clearly, a hierarchical data structure for the map would result in a clumsy representation involving much redundancy (Fig. 2.3(b, e)). Each coordinate pair would have to repeated twice and coordinates 3 and 4 would have to be repeated four times because line c has to be repeated twice. The structure is not only wasteful of space; it is clumsy, for if an operation were made to give polygons I and II the same name there is no easy way to suppress the display of line c. which would become unnecessary. These problems are avoided by the compact network structure shown in Fig. 2.3(c), in which each line and each coordinate need appear only once. With this structure it is a simple matter to suppress the printing of line e whenever it is referenced by polygons having the same name, thus making map generalization easier.
Very often in graphics, network structures are used that have a ring pointer structure. Ring pointer structures (Fig. 2.3(d)) are very useful ways of navigating around complex topological structures. Network systems are very useful when the relations or linkages can be specified beforehand. They avoid data redundancy and make good use of available data. The disadvantages are that the database is enlarged by the overhead of the pointers, which in complex systems can become quite a substantial part of the database. These pointers must be updated/maintained every time a change is made to the database and the building and maintenance of pointer structures can be a considerable overhead for the database system.
![Figura_2.3](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.3.png)
**Fig. 2.3** Network data structures for simple polygons. (a). The map M. (b) The two component polygons I and II. (c ) A network structure linking all polygons, lines, and points. (d) A ring pointer structure for M. (e) A hierarchical data structure for M.

*Relational database structures*
The relational database structure in its simplest form stores no pointers and has no hierarchy. Instead, the data are stored in simple records, known as tuples, containing an ordered set of attribute values that are grouped together in two-dimensional tables, known as relations. Each table or relation is usually a separate file. The pointer structures in network models and the keys in hierarchical structures are replaced by data redundancy in the form of identification codes that are used as unique keys to identify the records in each file (Fig. 2.4).
Data are extracted from a relational database through a procedure in which the user defines the relation that is appropriate for the query. This relation is not necessarily already present in the existing files. So, the controlling program uses the methods of relational algebra to construct the new tables.
Relational databases have the great advantage that their structure is very flexible and can meet the demands of all queries that can be formulated using the rules of Boolean logic and of mathematical operations. They allow different kinds of data to be searched, combined, and compared. Addition or removal of data is easy too, because this just involves adding or removing a tuple. The disadvantage of relational databases is that many of the operations involve sequential searches through the files to find the right data to satisfy the specified relations. This can involve a considerable amount of time with large databases, even on fast computers. Consequently, commercial relational database systems have to be very skilfully designed in order to support the search capabilities with reasonable speed, which is why they are so expensive. They are just beginning to be applied to geographical information systems (Abel 1983; Lorie and Meier 1984; van Roessel and Fosnight 1984).
![Figura_2.4](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.4.png)
**Fig. 2.4** A relational data structure for the map M.

*Record structures*
In all kinds of database structures, the data are written in the form of records. The simplest kind of record is a one-dimensional array of fixed length, divided into a number of equal partitions (Fig. 2.5(a)). This record is ideal when all items have the same number of attributes, for example when a number of soil profiles have been sampled and analysed for a standard range of cations. Fixed length records are inconvenient, however, when the attributes are of variable length, and when the set of attributes measured is not common to all items. For example, not all soil profiles have the same number of horizons, and not all polygon boundaries have the same number of coordinates. In these situations, variable length records are used. Each record has a "header", an extra attribute that contains information about the type of information in the sub-record and the amount of space it takes up (Fig. 2.5(b).
![Figura_2.5](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.5.png)
**Fig. 2.5** Two kinds of sequential list: (a) fixed length records; (b) variable length records including a "header" H to record data about the record itself.

**Perceived structures and computer representations of geographical data**
The human eye is highly efficient at recognizing shapes and forms, but the computer needs to be instructed exactly how spatial patterns should be handled and displayed. Essentially there are two contrasting, but complementary ways of representing spatial data in the computer that we shall refer to as explicit and implicit ways of describing spatial entities.
Figure 2.6 shows the two different ways in which a chair can be explicitly or implicitly represented in a computer. Explicit representation means that the form of the chair is built up from a set of points on a grid or raster. So that the computer knows that this set of points represents a chair and not a table, each cell is given the same code value "C". In practice, the C's would not be themselves displayed but would be represented by a numerical value or a colour or grey scale. We would then have the following simple data structure for the chair:
chair attribute $$\to$$ symbol/colour $$\to$$  cell X
The implicit representation makes use of a set of lines, defined by starting and end points and some form of connectivity. The starting and end points of the lines define rectors that represent the form of the chair; pointers between the lines indicate to the computer how the lines link together to form the chair. The data structure is:
chair attribute $$\to$$ set of vectors $$\to$$  connectivity.
Figure 2.6 also demonstrates several other differences between the two representations. First, the implicit representation requires fewer numbers, implying fewer storage spaces, to store the information about the chair (the vector representation uses $$11XY$$ pairs and 14 connecting pointers and the raster representation uses 60 cells). Second, the vector representation is aesthetically more pleasing than the raster image -- to produce an equivalent resolution the raster image would need to be based on a $$0.5 mm$$ grid, thereby requiring $$470 XY$$ pairs. Third, the connectivity information allows directed spatial searches to be made over the chair. On the other hand, if the shape or size of the chair has to be changed, this can be done much quicker and easier in the raster representation than in the vector. In a raster representation data update merely involves deleting certain values and writing in new ones. In vector representation, not only must the coordinates be updated but the connectivity must also be rebuilt.
We see that there are at least two fundamental ways of representing topological data which can be summarized as follows:
Raster representation -- set of cells located by coordinates; each cell is independently addressed with the value of an attribute.
Vector representation -- three main geographical entities, points, lines and areas: points are similar to cells, except they do not cover areas; lines and areas are sets of interconnected coordinates that can be linked to given attributes.
Note that there is no necessary or unique connection between the raster or vector structure of the geographical database and the raster or vector structure of the devices used to display the data, although this is very often the case. For example, most modern interactive computer-aided design and mapping systems work with vector-structured databases but use colour raster displays and vector plotters (see Chapter 4).
![Figura_2.6](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.6.png)
**Fig. 2.6** An image of a chair in (a) raster or grid-cell and (b) vector format.

**Raster data structures**
The simplest raster data structures consist of an array of grid cells (sometimes termed pixels or picture elements). Each grid cell is referenced by a row and column number, and it contains a number representing the type or value of the attribute being mapped. In raster structures a point is represented by a single grid cell; a line by a number of neighbouring cells strung out in a given direction and an area by an agglomeration of neighbouring cells. This type of data structure is easy to handle in the computer, particularly with programming languages such as FORTRAN, because of the ease with which arrays of rows and columns can be stored, manipulated, and displayed. This data structure also means that the two-dimensional surface upon which the geographical data are represented is not continuous, but quantized, which can have an important effect on the estimation of lengths and areas when grid cell sizes are large with respect to the features being represented. For example, Fig. 2.7(a) shows that the (Euclidean) distance between a and c is 5 units, while on Fig. 2.7(b), the distance between a and c could be 7 or 4 units depending on whether one counts cell edges or whole cells that must be traversed. The area of Fig. 2.7(a) is 6 units; the area of Fig. 2.7(b) is 7 units. We shall return to this problem of errors in Chapter 6. Because of the discrepancies that can arise in this way through the loss of precision associated with the cell size, many fields such as digital image processing often assume that the quantized surface can be treated as continuous, so that mathematical functions having derivatives that exist can be used (e.g. Castleman 1979).
Raster representation assumes that the geographical space can be treated as though it were a flat Cartesian surface. Each pixel or grid cell is then by implication associated with a square parcel of land. The resolution, or scale of the raster data is then the relation between the cell size in the database and the size of the cell on the ground.
![Figura_2.7](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.7.png)
**Fig. 2.7** Raster coding can affect estimates of distance and area because of the quantizing effect of the cells.

*Map overlays*
Because each cell in a two-dimensional array can only hold one number, different geographical attributes must be represented by separate sets of Cartesian arrays, known as "overlays". The overlay idea for separating data is not restricted to computer cartography. having been used by cartographers for preparing printed maps and by landscape planners (e.g. McHarg 1969) for a very long time. Figure. 2.8 illustrates the overlay concept in which each separate attribute is described and mapped separately.
In its simplest form, the overlay concept is realized in raster data structures by stacking two-dimensional arrays. This results in a three-dimensional structure as shown in Fig. 2.9. The overlay concept is essentially equivalent to the "picture function" in digital image processing (Duda and Hart 1973), a "data plane" in remote sensing (Tom et al. 1978) or image-based storage (O'Callaghan and Graetz 1981), and it is fundamental to most raster image processing.
![Figura_2.8](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.8.png)
**Fig. 2.8** The "overlay" concept; the real world is portrayed by a series of overlays in each of which one aspect of reality has been recorded (e.g. topography, soil type, roads, rivers, etc.).

![Figura_2.9](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.9.png)
**Fig. 2.9** Three-dimensional arrays used for coding map overlays in raster database structures.

*Referencing pixels in raster overlay structures*
Given that a raster map file is built up from what the user perceives as a number of Cartesian overlays, the question arises as to how these data can best be organized in the computer to optimize data access and to minimize storage and processing requirements. If each cell on each overlay is assumed to be an independent unit in the database (one-to-one relation between data value, pixel, and location) three basic and equivalent methods of organization are possible (Tomlin 1983). These are shown in Fig. 2.10. Figure 2.10(a) represents the structure used in the GRID program (Sinton and Steinitz 1969), the LUNR system (New York State Office of Planning Services 1972), and the MAGI system (Dangermond and Atenucci 1974). Each point on a map is represented as a vertical array in which each array position carries the value of the attribute associated with that overlay. Figure 2.10(b) represents the alternative method of representing each overlay as a two-dimensional matrix of points carrying the value of a single attribute. This method was used in IMGRID (Sinton 1977).
Figure 2.10(c) shows the hierarchical structure used by the Map Analysis Package (Tomlin 1983), which though formally equivalent to the other structures, has several advantages. Because of the many-to-one relation between attribute value and the set of points, for example, recoding a map requires rewriting only one number per mapping unit (the value). This is in contrast to the large number of recoding operations required when the other two structures are used.
*Compact methods for storing raster data*
When each cell has a unique value, it takes a total of n rows x m columns x 3 values (X, Y coordinates and attribute value) to encode each overlay. This is the situation with the altitude matrices used for digital terrain models. If sets of cells within a polygon or a mapping unit all have the same value, however, it is possible to effect considerable savings in the data storage requirements for the raster data, providing of course that the data structures are properly designed. The data structures described in Fig. 2.10(a, b) use the coordinates to reduce the actual quantity of numbers stored, with the limitation that all spatial operations must be carried out in terms of array row and column numbers. Because these systems do not encode the data in the form of a one-to-many relation between mapping unit value and cell coordinates, compact methods for encoding cannot be used. The third structure given in Fig. 2.10(c) references the sets of points per region (or mapping unit) and allows a variety of methods of compact storage to be used. There are four main ways in which compact storage can be achieved: these are by using chain codes, run-length codes, block codes, and quadtrees.
Chain codes. Consider Fig. 2.11. The boundary of the region can be given in terms of its origin and a sequence of unit vectors in the cardinal directions. These directions can be numbered (east =0, north=1, west=2, south=3). For example, if we start at cell row=10, column=1, the boundary of the region is coded clockwise by:
$$0, 1, 0^2, 3, 0^2, 1, 0, 3, 0, 1, 0^3, 3^2, 2, 3^3, 0^2, 1, 0^5, 3^2, 2^2, 3, 2^3, 3, 2^3, 1, 2^2, 1, 2^2, 1, 2^2, 1, 2^3, 1^3$$
where the number of steps (pixels) in each direction is given by the superscripted number. 
Chain codes provide a very compact way of storing a region representation and they allow certain operations such as estimation of areas and perimeters, or detection of sharp turns and concavities to be carried out easily. On the other hand, overlay operations such as union and intersection are difficult to perform without returning to a full grid representation. Another disadvantage is the redundancy introduced because all boundaries between regions must be stored twice. Freeman (1974) gives further details.
![Figura_2.10](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.10.png)
**Fig. 2.10** Three kinds of raster database structure. (a) Each cell is referenced directly. (b) Each overlay is referenced directly. (c) Each mapping unit or "region" is referenced directly.

![Figura_2.11](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.11.png)
**Fig. 2.11** A simple region on a rasterized map.

*Run-length codes.* Run-length codes allow the points in each mapping unit to be stored per row in terms, from left to right, of a begin cell and an end cell. For the area shown in Fig. 2.11 the codes would be as follows:
Row 9		2,3	6,6	8,10
Row 10		1,10
Row 11		1,9
Row 12		1,9
Row 13 	3,9	12,16
Row 14		5,16
Row 15		7,14
Row 16		9,11
In this example, the 69 cells of Fig. 2.11 have been completely coded by 22 numbers, thereby effecting a considerable reduction in the space needed to store the data.
Clearly, run-length coding is a considerable improvement in storage requirements over conventional methods whenever the many-to-one relations are present. It is especially suitable for use in small computers (e.g. Giltrap 1984) and where total volumes of data must be kept limited. On the other hand, too much data compression may lead to increased processing requirements during cartographic processing and manipulation.
Run-length codes are also useful in reducing the volume of data that need to be input to a simple raster database (see Chapter 4).
*Block codes.* The idea of run-length codes can be extended to two dimensions by using square blocks to tile the area to be mapped. Figure. 2.12 shows how this can be done for the raster map of Fig. 2.11. The data structure consists of just three numbers, the origin (the centre or bottom left) and radius of each square. This is called a medial axis transformation or MAT (Rosenfeld 1980). The region shown in Fig. 2.11 can be stored by 17 unit squares+9 4-squares+1 16- square. Given that two coordinates are needed for each square the region can be stored using 57 numbers (54 for coordinates and 3 for cell sizes). Clearly, the larger the square that can be fitted in any given region and the simpler the boundary, the more efficient block coding becomes. Both runlength and block codes are clearly most efficient for large simple shapes and least so for small complicated areas that are only a few times larger than the basic cell. Medial axis transformation has advantages for performing union and intersection of regions and for detecting properties such as elongation (Rosenfeld 1980).
For some operations, data stored in block or runlength codes must be converted to simple raster format.
*Quadtrees.* The fourth method of more compact representation is based on successive division of the $$2nx 2n$$ array into quadrants. A region is tiled by subdividing the array step by step into quadrants and noting which quadrants are wholly contained with the region. The lowest limit of division is the single pixel. Figure. 2.13 shows the successive division of the one region of Fig 2.11 intro quadrant blocks. This block structure can be described by a tree of degree 4, known as a quadtree, the quadtree representation of Fig. 2.11 is given in Fig. 2.14.
The entire array of $$2nx 2n$$ points is the root node of the tree, and the height of the tree is at most n levels. Each node has four branches, respectively the NW, NE, SW, and SE quadrants. Leaf nodes correspond to those quadrants for which no further subdivision is necessary. Each node in the quadtree can be represented by 2 bits, which define whether it is a terminator "in" ($$\uparrow \uparrow$$), a terminator “out” ($$\downarrow \downarrow$$) or node “in” at the current level ($$\uparrow \downarrow$$) or a node "out" at the current level ($$\downarrow \uparrow$$). So the region in Fig. 2.11 can be coded in 92 bits or 6 x 16-bit words.
Rosenfeld (1980). Klinger and Dyer (1976) and Hunter and Steiglitz (1979a, b) describe the use of quadtrees for region representation, and applications in soil and resource information systems are described by Abel (1983). Detailed descriptions of the algorithms used for computing perimeters and areas, and for converting from raster to quadtree and other representations have been described in a series of papers by Samet (1980, 1984). Dyer et al. (1980) and Pavlidis (1982). Quadtrees have many interesting advantages over other methods of raster representation. Standard region properties can be easily and efficiently computed. Quadtrees are “variable resolution” arrays in which detail is represented only when available without requiring excessive storage for parts where detail is lacking (Figs. 2.15(a-d), and 2.16.) The largest problems associated with quadtrees appear to be that the tree representation is not translation-invariant-two regions of the same shape and size may have quite different quadtrees, so consequently shape analysis and pattern recognition are not straightforward. Quadtree representation does allow a region to be split up into parts, or to contain holes, however, without difficulty. There is a growing interest in the use of quadtrees in geographical information systems (Samet et al. 1984; Martin 1982; Mark and Lauzon 1984) and it is clearly an elegant technique that has much to offer.
![Figura_2.12](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.12.png)
**Fig. 2.12** The simple region described by a medial axis transformation block coding.
![Figura_2.12](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.12.png)
**Fig. 2.13** The simple region as a quadtree.
![Figura_2.14](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.14.png)
**Fig. 2.14** The quadtree structure of the simple region of Fig 2.11.

*Summary -- raster data structures*
If each cell represents a potentially different value, then the simple NxN array structure is difficult to improve upon. Its limitations are largely related to the volume of data and size of memory required. When "regions" (ie. areas of uniform value) are present, as is assumed to be the case in many thematic maps, data storage requirements can be considerably reduced by using chain codes, run-length codes, block codes, or quadtrees. Run-length codes appear to be most efficient when the pixel size is large with respect to the area of the regions being displayed and sorted; as resolution improves and pixel numbers per region increase, however, block codes and quadtrees become increasingly attractive. The quadtree representation has the added advantage of variable resolution. The ease of subsequent processing varies with the data structure used.
![Figura_2.15](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.15.png)
**Fig. 2.15** The visual appearance of the simple region at each of the four levels of the quadtree hierarchy.

*Vector data structures for geographical entities*
As we saw earlier in this chapter, the vector representation of an object is an attempt to represent the object as exactly as possible. The coordinate space is assumed to be continuous, not quantized as with the raster space, allowing all positions, lengths, and dimensions to be defined precisely. In fact, this is not exactly possible because of the limitations of the length of a computer word on the exact representation of a coordinate and because all vector display devices have a basic step size, albeit very much smaller than the resolution of most raster devices. Besides the assumption of mathematically exact coordinates, vector methods of data storage use implicit relations that allow complex data to be stored in a minimum of space. There is no single, preferred method, however. This section explains a range of vector structures used in geographical information systems for the storage of points, lines, and areas.
![Figura_2.16](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.16.png)
**Fig. 2.16** A region divided by a quadtree structure. The area within the ellipse has detail shown to six levels of branching: the rest four.
![Figura_2.17](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.17.png)
**Fig. 2.17** Vector data structure of simple "point" entities.

*Point entities*
Point entities can be considered to embrace all geographical and graphical entities that are positioned by a single XY coordinate pair. Besides the XY coordinates, other data must be stored to indicate what kind of "point" it is, and the other information associated with it. For example, a "point" could be a symbol unrelated to any other information. The data record would have to include information about the symbol. and the display size and orientation of the symbol. If the "point" were a text entity, the data record would have to include information about the text characters to be displayed, the text font (style), the justification (right, left, centre), the scale, and the orientation, as well as ways of associating other non-graphic attributes with the "point". Figure 2.17 illustrates a possible data structure for "point" entities.
*Line entities*
Line entities can be defined as all linear features built up of straight line segments made up of two or more coordinates. The simplest line requires the storage of a begin point and an end point (two XY coordinate pairs) plus a possible record indicating the display symbol to be used. For example, the display symbol parameter could be used to call up solid or dashed lines on the display device even though all the segments of the dashed display had not been stored in the database.
An "arc", a "chain" or a "string" is a set of n XY coordinate pairs describing a continuous complex line. The shorter the line segments, and the larger the number of XY coordinate pairs, the closer the chain will approximate a complex curve. Data storage space can be saved at the expense of processing time by storing a number that indicates that the display driver routines should fit a mathematical interpolation function (e.g. B-splines) to the stored coordinates when the line data are sent to the display device.
As with "points" and simple lines, chains can be stored with data records indicating the type of display line symbol to be used.
Networks: simple lines and chains carry no inherent spatial information about connectivity such as might be required for drainage network analysis or for road and transport sites. To achieve a line network that can be traced by the computer from line to line it is necessary to build "pointers" into the data structure. The pointer structure is often built up with the help of nodes. Figure 2.18 illustrates the sort of data structure that would be necessary to establish connectivity between all branches of a stream network. Besides carrying pointers to the chains, the nodes would probably also carry data records indicating the angle at which each chain joins the node, thereby fully defining the topology of the network. This simple linkage structure incorporates some data redundancy because coordinates at each node are recorded a total of (nx chains + 1) times, where n is the number of chains joining a node.
![Figura_2.18](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.18.png)
**Fig. 2.18** Vector data structure of line networks using nodes to carry the connectivity information.

*Area entities*
Areas of polygons (sometimes called "regions") can be represented in various ways in a vector database. Because most kinds of thematic mapping used in geographical information systems have to do with polygons, the way in which these entities can be represented and manipulated has received considerable attention. The following discussion is largely based on the work of Peuker and Chrisman (1975), Cook (1978, 1983), Weber (1978), and Burrough (1980), and covers several well-known and frequently used methods of structuring polygon data.
The aim of a polygon data structure is to be able to describe the topological properties of areas (that is their shapes, neighbours, and hierarchy) in such a way that the associated properties of these basic spatial building blocks can be displayed and manipulated as thematic map data. Before describing the ways in which a polygon data structure can be constructed it would be as well to state the requirements of polygon networks that geographical data impose.
First, each component polygon (or region) on a map will have a unique shape, perimeter, and area. There is no single standard basic unit as is the case in raster systems. Even for the most regular or regularly laid out American street plan it will be unwise to assume that all or even some of the blocks have exactly the same shape and size. For soil and geological maps uniformity of space and size is clearly most unlikely. Second, geographical analyses require that the data structure be able to record the neighbours of each polygon in the same way that the stream network required connectivity. Third, polygons on thematic maps are not all at the same level -- islands occur in lakes that are themselves on large islands, and so on.
*Simple polygons*
The simplest way to represent a polygon is an extension of the simple chain, i.e. to represent each polygon as a set of XY coordinates on the boundary (Fig. 2.19). The names or symbols used to tell the user what each polygon is are then held as a set of simple text entities. While this method has the advantages of simplicity it has many disadvantages. These are:
1. Lines between adjacent polygons must be digitized and stored twice. This can lead to serious errors in matching, giving rise to slivers and gaps along the common boundary.
2. There is no neighbourhood information.
3. Islands are impossible except as purely graphical constructions.
4. There are no easy ways to check if the topology of the boundary is correct or whether it is incomplete ("dead-end") or makes topologically inadmissable loops (weird polygons") see Fig. 2.20.

The simple polygon structure can be extended such that each polygon is represented by a number of chains, but this does not avoid the basic problems.
![Figura_2.19](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.19.png)
**Fig. 2.19** Simple polygon structures have the disadvantage that boundary lines between two polygons have to be digitized and stored twice. This can lead to topological errors known as "slivers" and "gaps".
![Figura_2.20](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.20.png)
**Fig. 2.20** Topological errors in the boundary of a simple polygon. Incomplete linkages ("dead ends") and topologically inadmissible loops ("weird polygons") must be removed from the data.

*Polygons with point dictionaries*
All coordinate pairs are numbered sequentially and are referenced by a dictionary that records which points are associated with each polygon (Fig. 2.21(a)). This system is used by the Harvard Laboratory for Computer Graphics CALFORM program.
The point dictionary database has the advantage that boundaries between adjacent polygons are unique, but the problem of neighbourhood functions still exists. Also, the structure does not easily allow boundaries between adjacent polygons to be suppressed or dissolved if a renumbering or reclassification should result in them both being allocated to the same class. The problem of island polygons still exists, as do the problems of checking for weird polygons and dead ends. As with simple polygons, polygons can be used with chain dictionaries (Fig. 2.21(b)). An advantage of using chain dictionaries is that over-defined chains (resulting from stream digitizing) can be reduced in size by weeding algorithms (see Chapter 4) without having to modify the dictionary.
![Figura_2.21](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.21.png)
**Fig. 2.21 (a)** Polygon data structure in which all coordinates of a polygon are referenced directly from the polygon record. (b) The same, but all chains (arcs or boundary lines) are referenced directly from the polygon record.

*Polygon systems with explicit topological structures*
Islands and neighbours can only be properly handled by incorporating explicit topological relationships into the data structure. The topological structure can be built up in one of two ways -- by creating the topological links during data input, or by using software to create the topology from a set of interlinked chains or strings. In the first case, the burden of creating the topology is thrust on the operator, the second relies on often considerable amounts of computing power.
Both methods result in an increase in the amount of data that needs to be stored to describe the full polygon structure.
One of the first attempts to build explicit topological relationships into a geographical data structure is the Dual Independent Map Encoding (DIME) system of the US Bureau of the Census. The basic element of the DIME data file is a simple line segment defined by two end points: complex lines are represented by a series of segments. The segment has two pointers to the nodes, and codes for the polygon on each side of the segment. Because nodes do not point back to segments, or segments to adjacent segments, laborious searches are needed to assemble the outlines of polygons. Moreover, the simple segment structure makes the handling of complex lines very cumbersome because of the large data redundancy.
A simple, effective approach has been developed at the Netherlands Soil Survey Institute, Wageningen for distributing polygonal data sets in such a way that they can be processed by a small computer (van Kuilenburg 1981). The polygon map is stored as a segment or chain file in which each chain is stored as a list of XY coordinate pairs and two pointers that refer to the adjacent map areas (Fig. 2.22). The names of the polygons are stored in a separate table that also includes the same pointers. The data structure is specially designed for producing simple derivative maps from the basic polygon network. When a derived map is needed, the polygon names in the table are recoded. The plotter subroutines only allow a chain to be plotted or used for area calculations if its pointers reference different polygon names, thereby leading to a simplification of the original polygon network. Areas of polygons that contain islands are computed using a "point-in-polygon" search algorithm, to be described in more detail below. This data structure does not allow any more sophisticated neighbourhood searches to be made, nor does it allow error checks for weird polygons or dead ends, so it can best be derived from a fully topologically structured database.
![Figura_2.22](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.22.png)
**Fig. 2.22** Polygon data structure in which all polygons are referenced from the chains (arcs or boundary lines).

In order to establish a proper topological polygon data structure in which island polygons, area calculations, neighbourhood operations such as recoding and merging, and error checks for weird polygons and dead ends are all possible, the data structure shown schematically in Fig. 2.23 must be built up. Many experimental and production mapping systems have been designed in which the operator has been required to build the topological links into the database while digitizing the line pattern. These systems often require the operator to digitize all polygons in a strict clockwise or counter-clockwise order, to associate each line with the polygon on both right and left of the line and to digitize virtual lines to link "islands" with their surrounding "lakes". The developers of these systems have clearly never spent long hours at a digitizing table nor have they given much thought to how error-prone such a system may be. Cook (1978) documents some of the topological problems arising from the virtual line, such as with the calculation of areas and perimeters. Moreover, when highly detailed polygon maps have been produced by vectorizing a scanned raster image (see Chapter 4) it is clearly absurd that an operator should have to go over every part of the map by hand just to establish the topology. As White (1983) has complained, an elementary knowledge of topology can eliminate all the problems stated so far, but it must be fair to add that this has to be accompanied by an increase in the complexity of the software and of the resulting database.
![Figura_2.23](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.23.png)
**Fig. 2.23** A fuil topological network for polygons.

*A fully topological polygon network structure*
The following section describes how the fully integrated topologically linked polygon network structure shown in Fig. 2.23 can be built up from a set of boundary chains or strings that have been digitized in any order and in any direction. The system allows islands and lakes to be nested to any level; it allows automatic checks for weird polygons and dead ends and automated or semi-automated association of non-spatial attributes with the resulting polygons. Neighbourhood searches are fully supported. Although differing in details, the system that is about to be described is similar to systems used in the Harvard Polyvrt program (Peuker and Chrisman 1975), in CSIRO (Cook 1978) by Baxter (1980), Burrough (1980), and the CODASYL model (Weber 1978).
The simple polygon systems described so far often require data input methods to meet the requirements of the data structure. This leads to problems with data input and to sub-optimal data structures. It is more efficient to treat data input and data structure as two separate and independent processes. The procedures used to build the data structure should need only to make two assumptions of the input data, namely that the polygon boundaries have been encoded in the form of chains or arcs, and that the polygon names or other records used to link the graphical to the attribute data are digitized in the form of identifiable point entities somewhere within each polygon boundary.
*Stage 1*. Linking chains into a boundary network. The chains are first sorted according to their extents (minimum and maximum X and Y coordinates occupied by the chain) so that chains topologically close to one another are also close together in the data file. This is to save time when searching for adjacent chains. The chains are then examined to see which other chains they intersect. Junction points are built at the end of all chains that join, and the chain data records are extended to contain chain pointers and angles. Chains that cross at places other than the end points are automatically cut into new chains and the chain pointers are built. To handle minor digitizing errors such as overshoots and small gaps, a tolerance window can be built into the searching routine. The final end coordinates are then rewritten in all chain-end records as the average of all points found.
(Note: in some systems the nodes must be entered manually. Although this practice decreases processing times it results in extra work for data input, a nonstandard data format and redundancy in the database.)
*Stage 2.* Checking polygons for closure. The resulting network can easily be checked for closure by scanning the modified chain records to see if they all have pointers to and from at least another chain. The other chain may be the chain itself, in the case of single islands defined by a single chain. All chains failing to pass the test can be "flagged" (i.e. brought to the attention of the operator) by causing them to be displayed in a particular way, or otherwise be removed from the subset of chains to be used for the polygon network.
*Stage 3.* Linking the lines into polygons. The first step in linking lines into polygons is to create a new "envelope" polygon from the outer boundary of the map. This envelope entity consists of records containing:
 - (a) a unique identifier,
 - (b) a code that identifies it as an envelope polygon:
 - (c ) a ring pointer, 
 - (d) a list of pointers to the bounding chains;
 - (e) its area:
 - (f) its extent (minimum and maximum $$XY$$ coordinates of bounding rectangle).

Note that the envelope polygon will not be seen by the user -- its sole purpose is in building the topological structure of the network. The envelope polygon is created by following chains around the outer boundary by proceeding in a clockwise direction and choosing the most left-hand chain at each junction. The unique identifier of every chain is recorded and stored along with the other data and a flag is set to indicate that each chain has been traversed once.
Once the outer, or envelope, polygon has been built, each individual polygon can be created. This is done by starting at the same place as before, but this time the clockwise searches involve choosing the most right-hand chain at each junction. A tally must be kept of the number of times a chain has been traversed -- once it has been traversed twice it falls out of the search. Arriving back at the starting point, one has identified all the component lines. At the same time, a check is made on the cumulative turning angle (Fig. 2.20). If this is not 360 there has been a digitizing fault and the polygon is weird. (NB weird polygons should have been filtered out by the intersection-seek-ing step in Stage 1, but if the chains must be linked to manually entered nodes then this check is essential.) As with the envelope polygon, each polygon entity receives several sets of information:
- (a) a unique identifier,
- (b) an ordinary polygon code;
- (c ) a ring pointer from the envelope polygon (at the same time the identifier of this polygon is written in the ring pointer of the envelope polygon):
- (d) a list of all bounding chains (at the same time, the polygon's unique identifier is written into the record of the line);
- (e) a ring pointer to the adjacent polygon in the network:
- (f) minimum and maximum XY coordinates (extents) of the bounding rectangle.

The search proceeds to the next polygon in the same network at the same level in the hierarchy, and so on until all individual polygons have been built up. When the last polygon in the net has been traced, its ring pointer (e) is set pointing back to the envelope polygon. Note that this ensures that all bounding lines are associated with two polygons. 
The same procedure is followed for all “islands” and "unconnected sub-continents”. Once all bounding chains have been linked into polygons, the "islands" and the "sub-continents" must be arranged in the proper topological hierarchy. This can be done by first sorting them into increasing area, and then testing to see if an "island" falls within an "envelope" of the next largest size. A quick test can be made by comparing the extents of the two envelope polygons. Once a match has been found, the problem is to locate the exact polygon in which the island lies. The matching of extents is then repeated for each component polygon in the "continent". Once a match has been found, a "point-in- polygon" routine is used to see if the island is totally within the polygon (see Figs. 2.24 and 2.25). If an overlap is found, it signals an error in the database or the intersection procedures (Stage 1) and indicates that the operator must take remedial action. If there is no overlap, then a pointer is written from the network polygon to the envelope polygon of the enclosed island. If no overlap and no matching is found, it means that the two polygon networks are independent of each other. Note that the ring pointer structure of envelope polygons-network polygons-island envelope polygons-island network polygons allows an infinite amount of nesting. Moreover, the nesting only needs to be worked out once; thereafter the network can be traversed easily by following the pointers.
![Figura_2.24](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.24.png)
**Fig. 2.24** Solving the point-in-polygon problem. Point a is easily excluded because it is outside the extents (XY-min, XY-max). Points b and c need further processing.
![Figura_2.25](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.25.png)
**Fig. 2.25** If a horizontal line drawn from a point, d, makes an odd number of intersections with the polygon boundary then the point is "in". For polygons, the whole of the area of the small polygon must be scanned for enclosure.
*Stage 4.* Computing polygon areas. The next stage involves computing the area of the individual polygons by the trapezoidal rule. Because in geographical data, polygons may have many hundreds of coordinates in the bounding chains and many island polygons (imagine the geological map of an area with lakes and drumlins), it is usually more efficient to compute areas once, subtracting the areas of enclosed islands as necessary, and then to store these areas as an associated attribute.
*Stage 5.* Associating non-graphic attributes to the polygons. The last stage of building the database is to link the polygons to the associated attributes that describe what they represent. This can be done in several ways. The first is to digitize a unique text entity within each polygon area, either as part of the data entry, or interactively after polygons have been formed. This text can then be used as a pointer to the associated attributes that may or may not be stored with the graphic data. The text can be used for visual display, it is linked to the polygon by the use of a point-in-polygon search (see above, Fig. 2.25). The second is to get the computer to write the unique identifier of each polygon at the centre of each polygon; at the same time the computer prints a list of all polygon identifiers. This list can then be merged with a file containing the other non-graphic attributes of the polygons which can then be cross-referenced through the unique polygon identifiers.
The reader will appreciate that considerable computing power and complex software is needed to construct the topologically sound polygon network described above. The resulting data structure has the following advantages, however:
- (a) the polygon network is fully integrated and is free from gaps, slivers, and excessive amounts of redundant coordinates;
- (b) all polygons, chains, and associated attributes are part of an interlinked unit so that all kinds of neighbourhood analyses are possible (note that the system just described also allows the chains to have non-graphic attributes associated with them as well);
- (c ) the number of continent-island nestings is unlimited;
- (d) the locational accuracy of the database is limited only by the accuracy of the digitizer and the length of the computer word;
- (e) the data structure has few implications for data gathering and entry.

*Point-in-polygon search*
Figures 2.24 and 2.25 show two aspects of point-in-polygon algorithms. In Fig. 2.24, a quick comparison of the coordinates of the point with the polygon extents quickly reveals whether a point is likely to be in or not. So point a can easily be excluded but c cannot.
To check if point d is in the polygon in Fig. 2.25, a horizontal line is extended from the point. If the number of intersections is odd, the point is inside the polygon.
To check if an island polygon, P is inside P. first check the extents. P is then divided into a number of horizontal bands and the first and last points of each band are treated as the point c above. If the number of points for each line is odd, then the polygon P is completely enclosed. (NB Problems may occur if any segment of a boundary is exactly horizontal and has exactly the same Y coordinate as the point X, but these can be easily filtered out.)
Haralick (1980) lists an alternative procedure for finding the polygon containing a point that is based on a binary search of monotone chains -- that is, sequences of arcs in which the order of the vertices in the chain is the same as the order of the vertices projected onto a line.
*Other features of vector database structures*
*Layers.* When discussing raster database structures, it was noted how each attribute could be mapped as a separate overlay, giving rise to a three-dimensional data matrix. In principle, the number of layers is unlimited, restrictions being imposed only by storage space. The overlay concept is so natural to cartographers and designers that it is also frequently built into vector systems, particularly those that are used for computeraided design (CAD). Unlike raster systems, where each new attribute in the database means a new overlay, the overlay/layer system used in CAD vector systems is used to separate major classes of spatial entities, mainly for purposes of drawing and display.
The layer information is usually added to the graphic data by coding a bit sequence in a header that is attached to the data record of each graphic entity. Depending on the system, the bit sequences may allow 64 or 256 different layers for display; alternatively, the headers may be even more flexibly coded in terms of major non-graphic attributes that the user can define. such as railways, major roads, streams or soil boundaries (Fig. 2.26). The layer system makes it very easy to count, flag, and selectively display graphic entities. The landscape information system developed at The Netherlands Soil Survey Institute (Burrough 1980) uses Boolean selection rules to identify chosen graphic entities that can be isolated and displayed separately simply by changing the layer address.
![Figura_2.26](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.26.png)
**Fig. 2.26** Schematic view of the layer structures used in many vector mapping systems to separate different map themes. Each layer can be used to carry a separate theme. Different maps can be made by viewing layers singly, or in combination. Numbers refer to the "position" of the layers.

*Lists and sequential searches.* All the vector structures described up to now have only been concerned with relations between the points, chains, and polygons that go to make up the thematic map. The reader will have noted that in every case the basic entity, be it point, line or polygon, has been uniquely identified by a pointer or a label. The topological structures discussed can only be traversed by means of these unique labels.
These labels, sometimes called master index pointers, are often held in a sequential list that is the key to accessing the rest of the database (Fig. 2.27(a)). This list has two major problems associated with it. First, it is rarely fully consecutive -- during editing, gaps may appear, or it may be increased in length, which means that non-pointer searches almost invariably have to be of a sequential nature. Second, the search times increase sharply with the length of the table, which often means that map processing times increase non-linearly with the size of the database. This is not least the result of the master index table being distributed over a disk. Consequently, procedures that work well on small, demonstration databases may become very slow on production-size maps.
There are two fundamentally different ways to tackle the problem of an increasingly large database. One is to use "brute-force" computing methods to scan the pointer arrays quickly, or to concentrate the master index array onto a small, contiguous area of disk or core storage. While this approach can undoubtedly effect some improvements, it is at best a palliative and does little to resolve the underlying problems. Another approach involves structuring the master index pointers not only according to entity type, but also to spatial location (Fig. 2.27(b)). The database is considered to consist of an (in theory) infinite set of tiles reaching in both directions. Each tile (or page as it is sometimes called) can reference a certain amount of information; extra details can be accommodated by dividing each main tile into sub-tiles, in a manner similar to that used in quadtree structures (see Cook 1978). Tiling introduces an extra complication in that all chains must automatically be terminated and begun at tile boundaries, and topological pointers must not only reference other entities, but other tiles as well. The costs are thus a larger database, but one in which searching times can be kept very low by virtue of the positional hierarchy.
![Figura_2.27](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.27.png)
**Fig. 2.27** (a) Simple sequential data structure used for vector graphics. (b) Better design that splits database up into tiles (separate areas) and geographical entities.
In principle, tiling allows limitless maps to be created and stored, as only data from a few tiles need be referenced at any one time, the rest being stored on disk. In practice, the sheer volume of data will exceed the financially allowable disk space (it does not take many map sheets of soil polygons to fill 150 Mbyte) so that for countrywide mapping great reliance must be placed on magnetic tape for storing much of the total database until it is required.

**Data structures for thematic maps -- the choice between raster and vector**
The raster and vector methods for spatial data structures are distinctly different approaches to modelling geographical information, but are they mutually exclusive? Only a few years ago, the conventional wisdom was that raster and vector data structures were irreconcilable alternatives. They were then irreconcilable because raster methods required huge computer memories to store and process images at the level of spatial resolution obtained by vector structures. Certain kinds of data manipulation, such as polygon intersection or spatial averaging presented enormous technical problems with vector methods. The user was faced with the choice of raster methods that allowed easy spatial analysis but resulted in ugly maps, or vector methods that could provide databases of manageable size and elegant graphics but in which spatial analysis was extremely difficult.
In recent years it has become clear that what until recently was seen as an important conceptual problem is, in fact, a technological problem. When punched cards were the main medium of data storage, it was clearly an enormous task to code a 1:50000 scale soil series map measuring 400 x 500 mm at a resolution of 0.2mm (the line width on the printed map) because there would be 5x 10 pixels. These data would require something like 500 000 punched cards, assuming that each card could carry 10 coordinate pairs or pixels, which would occupy a volume of between two and three cubic metres! Today, it is commonplace for a good graphics colour screen to have an addressable raster array of 1024 x 1024 pixels within an area of some 300 x 300 mm, a resolution of 0.3 mm.
The quality of the graphics was not the only technological limitation. Most early technical developments were done in vector processing, simply because vector structures were the most familiar form of graphic expression. In the late 1970s, several workers, notably Peuquet (1977, 1979) and Nagy and Wagle (1979) showed that many of the algorithms that had been developed for vector data structures of polygonal data not only had raster alternatives, but that in some cases the raster alternatives were more efficient. For example, the calculation of polygon perimeters and areas, sums, averages, and other operations within a defined radius from a point are all reduced to simple counting operations in the raster mode. Because of the presorted and regular coordinate structure, windowing and clipping and the retrieval of items on the basis of location is easier in raster than in vector data structures. On the other hand, linked networks are really only feasible in the vector mode, so this is the preferred data structure for utility mapping or for analysing transport networks. Also, recent developments in faster algorithms for some vector-based operations have shown that there are more efficient ways to solve some problems than had previously been thought (Haralick 1980).
The gigantic storage volumes required for raster formats can also be greatly reduced by means of some of the compact raster data structures mentioned earlier in this chapter, such as run length codes or quadtrees. Conversely, the inclusion of a large amount of topological information in a vector network structure, or the redundancy in a relational data structure can seriously increase the size of vector-structured databases.
The problem of raster or vector disappears once it is realized that both are valid methods for representing spatial data, and that both structures are interconvertible. Conversion from vector to raster is the simplest and there are many well-known algorithms (e.g. Pavlidis 1982). Vector to raster conversions are now performed automatically in many display screens by inbuilt microprocessors. The reverse operation, raster to vector, is also well understood (Pavlidis lists four algorithms for thinning bands of pixels to lines), but it is a much more complex operation that is complicated by the need to reduce the numbers of coordinates in the resulting lines by a process known as weeding.
![Figura_2.28](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.28.png)
**Fig. 2.28** A simple map that can be represented in vector (arc-polygon) or raster form.

The original method of reducing the number of points in a digitized curve is due to Douglas and Peuker (1973); more recently Opheim (1982) has published a faster method. The point here is that whereas vector to raster conversion is a single-stage process, the converse is at best a two-stage process.
Haralick (1980), Shapiro (1980), and Shapiro and Haralick (1980) have shown in recent papers how a relational database structure for points, lines, and polygons can be established that treats the raster and vector approaches to modelling the topology as equivalent alternatives. The following discussion of this idea is based on Haralick's and on Shapiro's work, but includes a number of extensions to relate it to the material already discussed.
The idea rests on the understanding that attribute data and topological data should be kept separate from each other but can be easily linked. The attribute data that describe what the entity represents may include data about its real world attributes, and also about how the entity must be managed within the database. This last can also include information that governs the kinds of relations that a given spatial entity may have; for example, a point entity should not possess a record indicating its area, and a polygon entity should be defined in terms of records including information about the entities (boundaries or pixels) that describe it spatially.
The idea will be made clearer by an example. Consider Fig. 2.28. The polygon Pl is a part of a polygon network that we shall call "soil map". Pl contains two small inclusions (P2 and P3) and is surrounded by polygons P4, PS, and P7. There are At, attributes that refer to the properties of the space described by Pl. In vector notation, the space described by P1 is circumscribed by a boundary. It is part of Haralick and Shapiro's scheme that the boundary is an entity in its own right. The boundary consists of a number of arcs (A- A) (chains or strings in the notation used earlier in the chapter) that are themselves also entities. For both boundaries and arcs the entity data can be described by a set of relations. The permissible set of relations is governed by the entity type. In addition, each entity has an entity name in order to identify it uniquely.
In raster notation, the space described by Pl can be defined in terms of sets of pixels. As we have already seen there are several ways of defining pixel sets in raster mapping -- in this example we shall use the compact run length code method to describe the space defined by Pl. This method requires that the polygon be defined by an entity here called "pixels" containing the lists of rows that have pixels within the polygon; each pixel list is then an entity containing the begin and end indices of the sets of pixels in each row that form a part of the space of Pl.
Figure 2.29 shows how the polygon Pl can be represented fully in either raster or vector form. At the highest level, the polygon is described by a simple set of relations listing the entity name, the entity type, and the entity data. Whereas the name and type are simple records, the entity data is a set of relations including attributes, spatial relations, extents, and spatial description. Note that the entity data are identical in all respects for raster and vector notation, except for the set of relations referenced in the spatial description record.
In the vector notation, the boundary entity type is set up in a similar way to that of the polygon. The entity data relation contains attributes of the boundary, a list of the arcs making up that boundary and a list of the boundary entities of the holes within that boundary. The data structure for the arcs includes attributes indicating the polygons to their left and right, the boundary in which they belong, and a list of their coordinates.
![Figura_2.29](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Figura_2.29.png)
**Fig. 2.29** A possible relational database structure of Fig 2.28 for combined vector and raster representation.

This scheme contains a considerable amount of data redundancy in order to provide the linkages that are carried by pointers in the vector structures discussed earlier in the chapter.
In order to represent polygon Pl in raster notation, it is only necessary to change the entry in the record describing spatial description from "boundary" to "pixels". The pixel set is described in terms equivalent to those used for boundaries and arcs, except the pixel entities refer to sets of pixel lists on rows and to contiguous sets of pixels within rows (pixel lists).
Clearly, the main data structure of polygon Pl is unchanged by the way in which the space it occupies is described. Both the raster and vector representations of that space are equally valid data structures. If routines are available for the speedy conversion from one spatial structure to another, data retrieval and analysis routines can be programmed to choose the structure that is most efficient for solving a given problem without the user having to intervene (Table 22). In some circumstances it may be advantageous to have spatial data present in both raster and vector form, particularly when line or boundary data need to be represented by connected networks or drawn in a particular style and the spaces between must be filled with a print raster of a given symbolism or colour.
Bickmore (1984) describes an experimental coloured map of ecological zones in the Dolgellau area of North Wales made for the UK Nature Conservancy Council by the IGN in Paris that was made using combined raster and vector techniques. While this experiment referred only to making a map. we may expect that the use of vector and raster spatial data structures as complementary components of a geographical information system will increase in importance as demands for high resolution, compact data structures and the power of flexible data analyses increase.
![Table_2.2](https://github.com/angeljsus/tooltip-vanilla/blob/main/book/Table_2.2.png)
**Table 2.2** Comparison of vector and raster methods

